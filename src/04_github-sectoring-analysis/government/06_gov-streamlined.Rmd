---
title: "Untitled"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include = FALSE}
rm(list = ls())

for (pkg in c("tidyverse", "igraph", "data.table", "R.utils", "countrycode", "janitor",
              "RPostgreSQL", "cowplot", "maditr", "gt", "tidytext")) {library(pkg, character.only = TRUE)}

# connect to postgresql to get our data
conn <- dbConnect(drv = PostgreSQL(),
                  dbname = "sdad",
                  host = "10.250.124.195",
                  port = 5432,
                  user = Sys.getenv("db_userid"),
                  password = Sys.getenv("db_pwd"))

#github user with emails
gh_extra <- dbGetQuery(conn, "SELECT * FROM gh.ctrs_extra")

# disconnect from postgresql database
dbDisconnect(conn)

# goverment email domains
#https://home.dotgov.gov/data/ (All .gov domains)
#The official public list of .gov domains is updated about every two weeks:
#List of .gov domains - includes all federal, state, interstate, local, and tribal .gov and .fed.us domains.
email_domain_gov <- read_csv("~/git/oss-2020/data/government/email_domain_federal_full.csv") %>%
  rename("domain_name" = "Domain Name", "domain_type" ="Domain Type") %>%
  select(-"Security Contact Email", -"City", -"State") %>%
  mutate(domain_name = tolower(domain_name), gov = T) %>% 
  clean_names()

email_domain_gov <- email_domain_gov %>% 
  mutate(country_code = "us") %>% 
  add_row(domain_name = "fatec.sp.gov.br", domain_type = "City", agency = "Non-Federal Agency", 
          organization = "São Paulo State Faculty of Technology", gov = TRUE, country_code = "br") %>% 
  add_row(domain_name = "etec.sp.gov.br", domain_type = "City", agency = "Non-Federal Agency", 
          organization = "São Paulo State Escola Técnica Estadual", gov = TRUE, country_code = "br") %>% 
  add_row(domain_name = "digital.cabinet-office.gov.uk", domain_type = "Federal Agency", 
          agency = NA, organization = "UK Government Digital Service", gov = TRUE, country_code = "gb") %>% 
  add_row(domain_name = "digital.hmrc.gov.uk", domain_type = "Federal Agency", 
          agency = NA, organization = "UK Revenue and Customs", gov = TRUE, country_code = "gb") %>% 
  add_row(domain_name = "gov.bc.ca", domain_type = "Province", 
          agency = NA, organization = "Province of British Columbia", gov = TRUE, country_code = "ca") %>% 
  add_row(domain_name = "digital.justice.gov.uk", domain_type = "Federal Agency", 
          agency = NA, organization = "UK Ministry of Justice", gov = TRUE, country_code = "ca") %>% 
  add_row(domain_name = "digital.education.gov.uk", domain_type = "Federal Agency",
          agency = NA, organization = "UK Ministry of Education", gov = TRUE, country_code = "ca") %>%  
  add_row(domain_name = "mail.nih.gov", domain_type = "Federal Agency - Executive", 
          agency = "Department of Health and Human Services",
          organization = "National Institutes of Health", gov = TRUE, country_code = "us") %>% 
  add_row(domain_name = "ncbi.nlm.nih.gov", domain_type = "Federal Agency - Executive", 
          agency = "Department of Health and Human Services", 
          organization = "National Center for Biotechnology Information", gov = TRUE, country_code = "us") %>%
  add_row(domain_name = "niaid.nih.gov", domain_type = "Federal Agency - Executive", 
          agency = "Department of Health and Human Services", 
          organization = "National Institute of Allergy and Infectious Diseases", gov = TRUE, country_code = "us") %>%
  add_row(domain_name = "its.ny.gov", domain_type = "City", agency = "Non-Federal Agency", 
          organization = "New York State Office of Information Technology", gov = TRUE, country_code = "us") %>% 
  add_row(domain_name = "fda.hhs.gov", domain_type = "Federal Agency - Executive", 
          agency = "Department of Health and Human Services", 
          organization = "U.S. Food and Drug Administration", gov = TRUE, country_code = "us") %>%
  add_row(domain_name = "cms.hhs.gov", domain_type = "Federal Agency - Executive", 
          agency = "Department of Health and Human Services", 
          organization = "Centers for Medicare & Medicaid Services", gov = TRUE, country_code = "us") %>%
  add_row(domain_name = "contractor.usgs.gov", domain_type = "Federal Agency - Executive", 
          agency = "Department of the Interior", 
          organization = "United States Geological Survey", gov = TRUE, country_code = "us") %>% 
  rename(cc_from_email = country_code)

#email domain country from https://www.sitepoint.com/complete-list-country-code-top-level-domains/
email_domain_cc <- read_csv("~/git/oss-2020/data/government/email_domain_by_country.csv")
#remove dot in the email domain and add in country_code
email_domain_cc$email_domain <- str_replace_all(email_domain_cc$domain, fixed("."), "")
email_domain_cc$ctry_code <- countrycode(email_domain_cc$country_name, origin = 'country.name', destination = 'iso2c')

```

# Count of missingness

```{r}
gh_extra %>% drop_na(email) %>% count() / gh_extra %>% count()
gh_extra %>% drop_na(company) %>% count() / gh_extra %>% count()
gh_extra %>% drop_na(company, email) %>% count() / gh_extra %>% count()
```

# First lets classify gov users based on emails

```{r}
#match email adress domain
gh_email <- gh_extra %>%
  as.data.table() %>%
  # extracts all strings after @
  mutate(email_domain_full =  str_extract(email, "(?<=@).*")) %>%
  # new col with all missings
  mutate(is.gov = NA)

#construct a list of country email domain
email_domain_country_vector <- unlist(email_domain_cc$email_domain)
email_domain_country_pattern <- paste(email_domain_country_vector, collapse="$|")

#format into regex search pattern
email_domain_country_pattern <- paste("\\b(?i)(", email_domain_country_pattern, "$)\\b", sep="")

gh_email <- gh_email %>%
  #select(login, email, company, cc_multiple, email_domain_full)%>% # (might add cc_multiple later)
  #first part of the full domain
  mutate(email_domain_first = str_extract(email_domain_full, ".*(?=[.])"))%>%
  #match goverment email domain (gov, fed.us, mil)
  #note that we are matching any string that contains gov
  mutate(is_gov_email_domain = if_else(str_detect(email_domain_full, "\\b(?i)(gov|fed.us|.mil)\\b") == T, T, F)) %>%
  #filter(!is.na(email_domain_full))%>%
  #check if the the gh user email domain match the country domain list
  mutate(is.country_email_domain = if_else(str_detect(email_domain_full, email_domain_country_pattern) == T, T, F))%>%
  #extract the country email domain from the full email domain
  mutate(country_domain = if_else(is.country_email_domain, str_sub(email_domain_full,-2,-1), "NA"))%>%
  #add country name to the dataset by joining with the email domain data
  left_join(email_domain_cc, by = c("country_domain"="email_domain"))%>%
  rename(country_domain_name = ctry_code)

# get the count
table(gh_email$is_gov_email_domain)
#726 gh users had .gov (717) or fed.us (only 1), or .mil (only 8) emails

#join the cleaned email from gh with the gov email domain data
gh_email <- gh_email %>%
  left_join(email_domain_gov, by = c("email_domain_full" = "domain_name")) %>%
  #mutate(is.usgov = if_else(is.na(domain_type), F, T)) %>%
  dplyr::mutate(gov= replace_na(gov, FALSE))

gh_email <- gh_email %>%
  mutate(is.gov = if_else(is_gov_email_domain == T | gov==T, T, F))%>%
  select(-is_gov_email_domain, -gov)

table(gh_email$is.gov)
#consistent with the first match, 726 gh users are gov related

#There are 163 unique gov ending emails.
length(unique(filter(gh_email, is.gov)$email_domain_full))

gh_email %>%
  group_by(is.gov, is.country_email_domain )%>%
  summarize(N=n())

```


Basically, we found that 726 users can be classified into the government sector via email.

Second we will use the `company` column.

Step 2A: We are going to clean the company code by implementing all of Daniel's techniques

```{r}
# implementing daniel's approaches
legal_entities <- read.csv("~/git/oss-2020/data/ossPy-files/curatedLegalEntitesRaw.csv", header=FALSE)
legal_entities <- legal_entities %>%
  rename(strings = V1) %>%
  mutate(strings = as.character(strings))
legal_entities$strings <- substring(legal_entities$strings, 2)
legal_entities$strings <- substr(legal_entities$strings,1, nchar(legal_entities$strings)-1)

symbol_strings <- read.csv("~/git/oss-2020/data/ossPy-files/symbolRemove.csv", header=FALSE)
symbol_strings <- symbol_strings %>%
  rename(strings = V1) %>%
  mutate(strings = as.character(strings))
symbol_strings$strings <- substring(symbol_strings$strings, 2)
symbol_strings$strings <- substr(symbol_strings$strings,1, nchar(symbol_strings$strings)-1)
symbol_strings <- symbol_strings %>% slice(-17:-20)

curated_domains <- read.csv("~/git/oss-2020/data/ossPy-files/curatedDomains.csv", header=FALSE)
curated_domains <- curated_domains %>%
  rename(strings = V1) %>%
  mutate(strings = as.character(strings))
curated_domains$strings <- substring(curated_domains$strings, 2)
curated_domains$strings <- substr(curated_domains$strings,1, nchar(curated_domains$strings)-1)

gh_extra_company <- gh_email %>%
  mutate(company_original = company) %>%
  mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(legal_entities$strings),
                                                    "zqx|, Inc.)"), collapse = "|"), "")) %>%
  mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(symbol_strings$strings),
                                                    ", $|,$|zqx)"), collapse = "|"), "")) %>%
  mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(curated_domains$strings),
                                                    "zqx)"), collapse = "|"), "")) %>%
  mutate(company = tolower(company),
         company = trimws(company),
         company = str_replace_all(company, fixed("u.s."), "united states"),
         company = str_replace_all(company, "\\b(?i)( us|^us)\\b", "united states"),
         company = str_replace_all(company,"[^[:alnum:]]", " "))

gh_extra_company %>% 
  drop_na(organization)
```

Next we are going to pull out all of the strings that have already been matched and then use those to match others

```{r}
# pulls out the table of matching institutions from company_col
company_confirm_gov <- gh_extra_company %>%
  filter(is.gov == TRUE) %>%
  group_by(company) %>%
  summarize(N=n()) %>%
  filter(company != "") %>%
  filter(!is.na(company)) %>%
  arrange(desc(N)) %>%
  #cutoff threshold: 1
  filter(N > 1)

`%notin%` <- Negate(`%in%`)

company_confirm_gov <- company_confirm_gov %>%
  filter(company %notin% c("home office", "companieshouse", "oxford physics"))

#full string matching
company_confirm_gov_vector <- unlist(company_confirm_gov$company)
company_confirm_gov_pattern<- paste(company_confirm_gov_vector, collapse="|")
company_confirm_gov_pattern <- paste("\\b(?i)(", company_confirm_gov_pattern, ")\\b", sep="")

# apply the string matching technique
gh_extra_company <- gh_extra_company%>%
  mutate(company_match_gov = if_else(str_detect(company, company_confirm_gov_pattern) == T, T, F))%>%
  mutate(company_match_gov= replace_na(company_match_gov, FALSE)) %>%
  mutate(is.gov = if_else(company_match_gov==T, T, is.gov))

gh_extra_company <- gh_extra_company %>%
  rename(domain_name = email_domain_full) %>% 
  mutate(company = replace_na(company, "recode_org")) %>% 
  mutate(company = ifelse(str_detect(company, "recode_org"), organization, company)) %>% 
  mutate(company = tolower(company)) %>% 
  select(login, email, company, everything())  

gh_extra_company %>%
  filter(is.gov == TRUE) %>%
  count(company) %>%
  arrange(-n)

table(gh_extra_company$is.gov)

```

```{r}

# load local functions 
source("~/git/oss-2020/scripts/standardize_gov.R")

gh_stand_gov <- gh_extra_company %>%
  mutate(institution = company) %>% 
  standardize_gov(gh_extra_company$institution) %>% 
  mutate.(possible_gov = if_else(company_original == institution, FALSE, TRUE)) %>% 
  select(login, institution, possible_gov, everything()) 


gh_stand_gov %>% 
  as.tibble() %>% 
  select(login, company, institution, possible_gov, everything()) %>% 
  filter(possible_gov == TRUE) %>% 
  count(institution) %>% 
  arrange(-n)

gh_stand_gov %>% 
  as.tibble() %>% 
  select(login, institution, everything()) %>% 
  filter(is.gov == TRUE)

gh_stand_gov %>% 
  select(company_original, institution) %>% 
  mutate.(possible_gov = if_else(company_original == institution, FALSE, TRUE))


gh_extra_company %>% 
  select(login, company_original, domain_name) %>% 
  filter(grepl("microsoft", domain_name)) %>% 
  count(company_original) %>% 
  arrange(-n)
  
gh_extra_company %>% 
  select(domain_name) %>% 
  filter(grepl("stanford", domain_name)) %>% 
  count(domain_name) %>% 
  arrange(-n)

```


















## Bag of words (singleton/bigrams) matching
## worked during the summer but did not work after = too many false positives 

```{r}
#companies names listed by previously identified users in government sector
company_list <- gh_extra_company%>%
  filter(is.gov)%>%
  select(company)%>%
  filter(!is.na(company))

#bigrams
company_list_bigrams <- company_list %>%
  unnest_tokens(bigram, company, token = "ngrams", n = 2)%>%
  count(bigram, sort=T) %>%
  filter(n > 1)
company_list_bigrams_vector <- unlist(company_list_bigrams$bigram)

#trigrams
company_list_trigrams <- company_list %>%
  unnest_tokens(trigram, company, token = "ngrams", n = 3)%>%
  count(trigram, sort=T)

#quatrigrams
company_list_quatrigrams <- company_list %>%
  unnest_tokens(quatrigram, company, token = "ngrams", n = 4)%>%
  count(quatrigram, sort=T)


false_positives <- c("united states", "research center", "home office", "university of", "the university", "of technology",
                     "faculty of",
                     "state university", "university chicago", "columbia university", "laboratory university",
                     "university manchester", "university washington", "university brookhaven", "uc berkeley") 
#note that we don't want to exclude strings that include university since there are useful ones, which induces false negatives. hereby we manually write out false positive ones. 
company_list_bigrams_vector <- setdiff(company_list_bigrams_vector, false_positives)


company_list_bigrams_vector_pattern<-paste(company_list_bigrams_vector, collapse="|")

company_list_bigrams_vector_pattern <- paste("\\b(?i)(", company_list_bigrams_vector_pattern, ")\\b", sep="")

gh_extra_company <- gh_extra_company %>%
  mutate(bigram_match_company = if_else(str_detect(company, company_list_bigrams_vector_pattern) == T, T, F))%>%
  mutate(bigram_match_company= replace_na(bigram_match_company, FALSE))
#table(gh_extra_company$bigram_match_company)
table(filter(gh_extra_company, !is.gov)$bigram_match_company)

gh_extra_company <- gh_extra_company%>%
  mutate(is.gov = if_else(bigram_match_company==T, T, is.gov))

table(gh_extra_company$is.gov)

#singletons
bag_of_words <- as.data.frame(unlist(strsplit(company_list$company, "\\ ")))
colnames(bag_of_words) <- "company"
bag_of_words <- bag_of_words%>%
  group_by(company)%>%
  summarize(N=n())

gh_extra_company %>% 
  filter(is.gov == TRUE) %>%
  count(company) %>% 
  arrange(-n)
```








```{r}
gh_extra_company %>%
  filter(is.gov == TRUE & is.na(company)) %>% 
  count(domain_name) %>% 
  arrange(-n)
```

```{r}

# to add 9/14
# ufrn.edu.br = Colombian education dept
# Interpol, United Nations, etc can all have multiple countries attached to organization
```













