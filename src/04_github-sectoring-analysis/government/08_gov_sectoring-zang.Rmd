---
title: "02_name_cleaning"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
# to add 9/14
# province of british columbia
# ufrn.edu.br = Colombian education dept 

```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
for (pkg in c("tidyverse", "igraph", "data.table", "R.utils", "RPostgreSQL", "cowplot", "maditr", "gt", "tidytext")) {library(pkg, character.only = TRUE)}

# connect to postgresql to get our data
conn <- dbConnect(drv = PostgreSQL(), 
                  dbname = "sdad", 
                  host = "10.250.124.195",
                  port = 5432, 
                  user = Sys.getenv("db_userid"), 
                  password = Sys.getenv("db_pwd"))

#github user with emails
gh_extra <- dbGetQuery(conn, "SELECT *
                              FROM gh.ctrs_extra")


# query the users_gh data (table of all github users) 
us_gov_ffrdcs <- dbGetQuery(conn, "SELECT * FROM us_gov_depts.us_gov_ffrdcs")

# check <- us_gov_ffrdcs %>%
#   group_by(Admin_Name)%>%
#   summarize(N=n())%>%
#   arrange(desc(N))
# write.csv(check, file="gov_admin.csv")
# query the users_gh data (table of all github users) 
us_gov_azindex <- dbGetQuery(conn, "SELECT * FROM us_gov_depts.us_gov_azindex_clean")

# query the users_gh data (table of all github users) 
us_gov_manual <- dbGetQuery(conn, "SELECT * FROM us_gov_depts.us_gov_manual")

# query the email domain data
#email_domain_datahub <- dbGetQuery(conn, "SELECT * FROM datahub.domain_names")

# goverment email domains
#https://home.dotgov.gov/data/ (All .gov domains)
#The official public list of .gov domains is updated about every two weeks:
#List of .gov domains - includes all federal, state, interstate, local, and tribal .gov and .fed.us domains.
email_domain_gov <- read_csv("/sfs/qumulo/qhome/zz3hs/oss-data/email_domain_federal_full.csv")%>%
   rename("domain_name" = "Domain Name", "domain_type" ="Domain Type")%>%
  select(-"Security Contact Email", -"City", -"State")%>%
  mutate(domain_name = tolower(domain_name), gov = T)


#email domain country
#https://www.sitepoint.com/complete-list-country-code-top-level-domains/
email_domain_cc <- read.delim("/sfs/qumulo/qhome/zz3hs/oss-data/email_domain_country.txt")
email_domain_cc <- rbind(colnames(email_domain_cc), email_domain_cc)
colnames(email_domain_cc) <- "email_domain"
email_domain_cc$country_code <- "NA" #initialize a column of NA

# identify rows that contain a dot in the string (email domain) 
# shift the row below the previously identified rows to the new column to have matched country email domain with the country name
for (i in (1:nrow(email_domain_cc))){
  cc_i <- email_domain_cc[i,1]
  if(grepl(".", cc_i, fixed = T)){
    email_domain_cc[i, 2] = email_domain_cc[i+1, 1]
  }else{
    email_domain_cc[i, 2] =NA
  }
}
email_domain_cc <- email_domain_cc%>%
  filter(!is.na(country_code))

#remove dot in the email domain
email_domain_cc$email_domain <- str_replace_all(email_domain_cc$email_domain, fixed("."), "") 

# disconnect from postgresql database 
dbDisconnect(conn)
```

# A count of missingness
```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
gh_extra_not_na_email <- gh_extra %>%
 filter(!is.na(email))

nrow(gh_extra_not_na_email) 
nrow(gh_extra_not_na_email) /nrow(gh_extra) *100

gh_extra_not_na_company <- gh_extra %>%
 filter(!is.na(company))

nrow(gh_extra_not_na_company) 
nrow(gh_extra_not_na_company) /nrow(gh_extra) *100


gh_extra_not_na <- gh_extra %>%
 filter(!is.na(email) | !is.na(company))
nrow(gh_extra_not_na) 
nrow(gh_extra_not_na) /nrow(gh_extra) *100
```

# Split github user data into users with email and users with no email
```{r}
#match email adress domain
gh_extra <- gh_extra%>%
  as.data.table()%>%#convert to data table
  mutate(email_domain_full =  str_extract(email, "(?<=@).*")) #all strings after @

gh_extra_email <- gh_extra%>%  
  filter(!is.na(email_domain_full))

nrow(gh_extra_email)
nrow(gh_extra_email)/nrow(gh_extra) #27% of github users had email address

##github users don't have emails
gh_extra_no_email <- gh_extra%>%
  filter(is.na(email_domain_full))%>%
  select(login, email, company, cc_multiple) %>% #prepare for a join
  mutate(is.gov = NA)

nrow(gh_extra_no_email)
```

# Matching
## Email domain matching
Match email address country domain, gov|fed.us|.mi matching
```{r}
#construct a list of country email domain
email_domain_country_vector <- unlist(email_domain_cc$email_domain)
email_domain_country_pattern <- paste(email_domain_country_vector, collapse="$|")

#format into regex search pattern
email_domain_country_pattern <- paste("\\b(?i)(", email_domain_country_pattern, "$)\\b", sep="")

gh_extra_email <- gh_extra_email %>%
  select(login, email, company, cc_multiple, email_domain_full)%>% #might add cc_multiple later
  mutate(email_domain_first = str_extract(email_domain_full, ".*(?=[.])"))%>% #first part of the full domain
  #match goverment email domain (gov, fed.us, mil)
  mutate(is_gov_email_domain = if_else(str_detect(email_domain_full, "\\b(?i)(gov|fed.us|.mil)\\b") == T, T, F)) %>% #note that we are matching any string that contains gov 
  filter(!is.na(email_domain_full))%>%
  #check if the the gh user email domain match the country domain list
  mutate(is.country_email_domain = if_else(str_detect(email_domain_full, email_domain_country_pattern) == T, T, F))%>%
  #extract the country email domain from the full email domain 
  mutate(country_domain = if_else(is.country_email_domain, str_sub(email_domain_full,-2,-1), "NA"))%>%
  #add country name to the dataset by joining with the email domain data
  left_join(email_domain_cc, by = c("country_domain"="email_domain"))%>%
  rename(country_domain_name = country_code)

# email_clean_is_country_email_domain <- gh_extra_email%>%
#   filter(is.country_email_domain) %>%
#   mutate(match_country_code = if_else(cc_multiple ==country_domain, T, F))
# 
# table(is.na(email_clean_is_country_email_domain$cc_multiple)) #26053 github users don't have country code(cc_multiple) but has country related email domain

# check <- email_clean_is_country_email_domain %>%
#   filter(is.na(cc_multiple))%>%
#   group_by(country_domain)%>%
#   summarize(count = n())%>%
#   arrange(desc(count))
# 
# check <- email_clean_is_country_email_domain %>%
#   group_by(email_domain_first)%>%
#   summarize(count = n())%>%
#   arrange(desc(count))
###
table(gh_extra_email$is_gov_email_domain) #726 gh users had .gov (717) or fed.us (only 1), or .mil (only 8) emails


#join the cleaned email from gh with the gov email domain data
gh_extra_email <- gh_extra_email%>%
  left_join(email_domain_gov, by = c("email_domain_full" = "domain_name"))%>%
  mutate(is.usgov = if_else(is.na(domain_type), F, T))%>%
  dplyr::mutate(gov= replace_na(gov, FALSE))

table(gh_extra_email$gov, gh_extra_email$is_gov_email_domain) #430 gh users matched with the email_domain_gov, 296 didn't match (these might be foreign gov)

gh_extra_email <- gh_extra_email %>%
  mutate(is.gov = if_else(is_gov_email_domain == T | gov==T, T, F))%>%
  select(-is_gov_email_domain, -gov)

table(gh_extra_email$is.gov) #consistent with the first match, 726 gh users are gov related

#table of the top gov email domains
# gh_extra_email%>%
#   filter(is.gov)%>%
#   group_by(email_domain_full)%>%
#   summarize(domain_type = unique(domain_type), agency=first(Agency), organization = first(Organization), N=n(),  `percent(%)` = round(100* N/nrow(email_clean), digits= 2))%>%
#   arrange(desc(N))%>%
#   mutate(sum = sum(N))%>%
#   top_n(20, N)%>%
#   select(-sum)%>%
#   gt()

#There are 163 unique gov ending emails. 
length(unique(filter(gh_extra_email, is.gov)$email_domain_full))

gh_extra_email%>%
  group_by(is.gov,is.usgov, is.country_email_domain )%>%
  summarize(N=n())

#did not match either us gov domain or country code
# check<- gh_extra_email%>%
#   filter(is.gov & !is.usgov & !is.country_email_domain)%>%
#   group_by(email_domain_full)%>%
#   summarize(N=n())%>%
#   arrange(desc(N))
gh_extra_email_final <- gh_extra_email%>%
  select(login, email, company, cc_multiple, is.gov)
```

## Full-string matching on identified company names from users previously identified in government sector using email domain
```{r}
gh_extra_company <- rbind(gh_extra_no_email, gh_extra_email_final)
nrow(gh_extra_company)
#company cleaning
gh_extra_company <- gh_extra_company%>%
    mutate(company = tolower(company))
gh_extra_company$company <- str_replace_all(gh_extra_company$company, fixed("u.s."), "united states") 

gh_extra_company$company <- str_replace_all(gh_extra_company$company, "\\b(?i)( us|^us)\\b", "united states")  #note here we have "space us" to avoid catch .us email domain in the company  name. Also note that u.s. pattern can't be identified

#remove all non-alphanumeric characters in the company string
gh_extra_company$company <- str_replace_all(gh_extra_company$company,"[^[:alnum:]]", " ") 

gh_extra_company$c_company <- str_replace_all(gh_extra_company$company, "\\b(?i)(of|and|the|de|for|at|with|from|to|in|on|by|about|as)\\b", "")  

#remove leading space induced by the previous step
gh_extra_company$c_company <- trimws(gh_extra_company$c_company) 

company_confirm_gov <- gh_extra_company%>%
  filter(is.gov)%>%
  group_by(c_company)%>%
  summarize(N=n())%>%
  filter(c_company != "")%>%
  filter(!is.na(c_company))%>%
  arrange(desc(N))%>%
  filter(N > 1) #cutoff threshold: 1

#full string matching
company_confirm_gov_vector <- unlist(company_confirm_gov$c_company)

company_confirm_gov_pattern<-paste(company_confirm_gov_vector, collapse="|")

company_confirm_gov_pattern <- paste("\\b(?i)(", company_confirm_gov_pattern, ")\\b", sep="")

gh_extra_company <- gh_extra_company%>%
  mutate(company_match_gov = if_else(str_detect(c_company, company_confirm_gov_pattern) == T, T, F))%>%
  mutate(company_match_gov= replace_na(company_match_gov, FALSE))

table(filter(gh_extra_company, !is.gov)$company_match_gov)


gh_extra_company <- gh_extra_company%>%
  mutate(is.gov = if_else(company_match_gov==T, T, is.gov))

table(gh_extra_company$is.gov)
```

## Bag of words (singleton/bigrams) matching
```{r}
#companies names listed by previously identified users in government sector
company_list <- gh_extra_company%>%
  filter(is.gov)%>%
  select(c_company)%>%
  filter(!is.na(c_company))

#bigrams
company_list_bigrams <- company_list %>%
  unnest_tokens(bigram, c_company, token = "ngrams", n = 2)%>%
  count(bigram, sort=T) %>%
  filter(n > 1)
company_list_bigrams_vector <- unlist(company_list_bigrams$bigram)

#trigrams
company_list_trigrams <- company_list %>%
  unnest_tokens(trigram, c_company, token = "ngrams", n = 3)%>%
  count(trigram, sort=T)

#quatrigrams
company_list_quatrigrams <- company_list %>%
  unnest_tokens(quatrigram, c_company, token = "ngrams", n = 4)%>%
  count(quatrigram, sort=T)




false_positives <- c("united states", "research center", "home office", "state university", "university chicago", "columbia university", "university manchester", "university washington", "university brookhaven") #note that we don't want to exclude strings that include university since there are useful ones, which induces false negatives. hereby we manually write out false positive ones. 
company_list_bigrams_vector <- setdiff(company_list_bigrams_vector, false_positives)


company_list_bigrams_vector_pattern<-paste(company_list_bigrams_vector, collapse="|")

company_list_bigrams_vector_pattern <- paste("\\b(?i)(", company_list_bigrams_vector_pattern, ")\\b", sep="")

gh_extra_company <- gh_extra_company%>%
  mutate(bigram_match_company = if_else(str_detect(c_company, company_list_bigrams_vector_pattern) == T, T, F))%>%
  mutate(bigram_match_company= replace_na(bigram_match_company, FALSE))
#table(gh_extra_company$bigram_match_company)
table(filter(gh_extra_company, !is.gov)$bigram_match_company)
gh_extra_company <- gh_extra_company%>%
  mutate(is.gov = if_else(bigram_match_company==T, T, is.gov))

table(gh_extra_company$is.gov)

#singletons
bag_of_words <- as.data.frame(unlist(strsplit(company_list$c_company, "\\ ")))
colnames(bag_of_words) <- "company"
bag_of_words <- bag_of_words%>%
  group_by(company)%>%
  summarize(N=n())
```

## U.S. Government Department/Agency name matching
```{r}
#I.azindex
#I.1 agency
az_list_agency <- distinct(us_gov_azindex, agency) %>% 
  rename(institution = agency)%>%
  mutate(dataset = "azindex_agency")

##I.2gov agency
az_list_gov_agency <- distinct(us_gov_azindex, gov_agency) %>%
  rename(institution = gov_agency)%>%
  mutate(dataset = "azindex_gov_agency")

##I.3gov branch
az_list_gov_branch <- distinct(us_gov_azindex, gov_branch)%>%
  rename(institution = gov_branch)%>%
  mutate(dataset = "azindex_gov_branch")%>%
  filter(institution != "None")

##I.4 child agency
az_list_child_agency <- distinct(us_gov_azindex, child_agency)%>%
  rename(institution = child_agency)%>%
  mutate(dataset = "azindex_child_agency")


#II. ffrdc
##II.1 FFRDC
ffrdc_list <- distinct(us_gov_ffrdcs, FFRDC_Name)  %>% 
  rename(institution = FFRDC_Name)%>%
  mutate(dataset = "ffrdc" )

##II.2 agency
ffrdc_list_agency <- us_gov_ffrdcs%>%
  select(Agency, Agency2, Agency3)%>%
  gather("agency_type", "agency_name")%>%
  filter(!is.na(agency_name))%>%
  distinct(agency_name) %>% 
  rename(institution = agency_name)%>%
  mutate(dataset = "ffrdc_agency")

##II.3 sub agency
ffrdc_list_sub_agency <- us_gov_ffrdcs%>%
  select(FFRDC_Name, Sub_Agency, Sub_Agency2, Sub_Agency3)%>%
  gather("agency_type", "agency_name")%>%
  filter(!is.na(agency_name))%>%
  distinct(agency_name)%>% 
  rename(institution = agency_name)%>%
  mutate(dataset = "ffrdc_sub_agency" )

##II.4. 
ffrdc_list_admin <- us_gov_ffrdcs%>%
  select(Admin_Name)%>%
  filter(!is.na(Admin_Name))

ffrdc_list_admin$Admin_Name <- str_replace_all(ffrdc_list_admin$Admin_Name, fixed("Corp."), "Corporation") 

`%notin%` <- Negate(`%in%`)

ffrdc_list_admin <- ffrdc_list_admin %>%
  distinct(Admin_Name) %>% 
  rename(institution = Admin_Name)%>%
  mutate(dataset = "ffrdc_admin")%>%
  filter(institution %notin% c("University of California", "Stanford University", "Princeton University", "Massachusetts Institute of Technology", "Iowa State University", "Carnegie Mellon University", "California Institute of Technology"))

  
#III.usman
usman_list <- us_gov_manual%>%
  distinct( AgencyName)  %>% 
  rename(institution = AgencyName)%>%
  mutate(dataset = "usman")


# bind all lists
all_lists <- rbind(az_list_agency, az_list_gov_agency, az_list_gov_branch, az_list_child_agency, ffrdc_list_agency, ffrdc_list_sub_agency, ffrdc_list_admin, usman_list)
#all_lists <- distinct(all_lists, institution, .keep_all = TRUE) #exclude duplicates


abb_ls <- str_extract_all(all_lists$institution, "\\(.+?\\)")
abb_ls[abb_ls=="character(0)"] <- NA
institution_abb <- unlist(abb_ls)

#extract abbreviation
all_lists_clean <- cbind(all_lists, institution_abb)

all_lists_clean$institution <- sub(" *\\(.*", "", all_lists_clean$institution)

all_lists_clean$institution_abb <- str_replace_all(all_lists_clean$institution_abb , fixed("("), "") 
all_lists_clean$institution_abb <- str_replace_all(all_lists_clean$institution_abb , fixed(")"), "") 
# table(duplicated(all_lists_clean$institution))
# check <- all_lists_clean %>%
#   group_by(institution)%>%
#   summarize(N=n())

abb <- all_lists_clean%>%
  filter(!is.na(institution_abb))%>%
  select(institution, institution_abb)

all_lists_clean_final <- all_lists_clean%>%
  left_join(abb, by = "institution")%>%
  select(-institution_abb.x)%>%
  rename(institution_abb = institution_abb.y)

#write.csv(all_lists_clean_final, file = "us_gov_name_list.csv")

#deduplicate
all_lists_clean <- distinct(all_lists_clean, institution, .keep_all = TRUE) #exclude duplicates

#institution cleaning, the same as gh company name cleaning
all_lists_clean <- all_lists_clean%>%
    mutate(institution = tolower(institution))%>% 
   filter(!is.na(institution))

all_lists_clean$institution <- str_replace_all(all_lists_clean$institution, fixed("u.s."), "united states") 

all_lists_clean$institution <- str_replace_all(all_lists_clean$institution, "\\b(?i)( us|^us)\\b", "united states")  #note here we have "space us" to avoid catch .us email domain in the company  name. Also note that u.s. pattern can't be identified

#remove all non-alphanumeric characters in the company string
all_lists_clean$institution <- str_replace_all(all_lists_clean$institution,"[^[:alnum:]]", " ") 

all_lists_clean$c_institution <- str_replace_all(all_lists_clean$institution, "\\b(?i)(of|and|the|de|for|at|with|from|to|in|on|by|about|as)\\b", "")  

#remove leading space induced by the previous step
all_lists_clean$c_institution <- trimws(all_lists_clean$c_institution) 

all_lists_clean <- all_lists_clean%>%
  mutate(num_alp = str_length(c_institution))%>%
  filter(num_alp >2)   #fix duplicates

all_lists_clean <- distinct(all_lists_clean, c_institution, .keep_all = TRUE) #exclude duplicates


gov_name <- all_lists_clean$c_institution
false_positives <- "mint"

gov_name_vector <- setdiff(gov_name, false_positives)

###Unlist
gov_name_vector <- unlist(all_lists_clean$c_institution)
gov_name_pattern <- paste(gov_name_vector,collapse="|" )
gov_name_pattern <- paste("\\b(?i)(", gov_name_pattern, ")\\b", sep="")

gh_extra_company <- gh_extra_company%>%
  mutate(gov_name_match_company = if_else(str_detect(c_company, gov_name_pattern) == T, T, F))%>%
  mutate(gov_name_match_company= replace_na(gov_name_match_company, FALSE))

nrow(filter(gh_extra_company, !is.gov, gov_name_match_company == T))



gh_extra_company <- gh_extra_company%>%
  mutate(is.gov = if_else(gov_name_match_company==T, T, is.gov))
table(gh_extra_company$is.gov)
```

## Bag of words (singleton/bigrams) matching
```{r}
#companies names listed by previously identified users in government sector
institution_list <- all_lists_clean%>%
  select(c_institution)

#bigrams
institution_list_bigrams <- institution_list %>%
  unnest_tokens(bigram, c_institution, token = "ngrams", n = 2)%>%
  count(bigram, sort=T) %>%
  filter(n > 1)
institution_list_bigrams_vector <- unlist(institution_list_bigrams$bigram)

#trigrams
institution_list_trigrams <- institution_list %>%
  unnest_tokens(trigram, c_institution, token = "ngrams", n = 3)%>%
  count(trigram, sort=T)

#quatrigrams
company_list_quatrigrams <- institution_list %>%
  unnest_tokens(quatrigram, c_institution, token = "ngrams", n = 4)%>%
  count(quatrigram, sort=T)

#todo
#false_positives <- c() 
# institution_list_bigrams_vector <- setdiff(institution_list_bigrams_vector, false_positives)


institution_list_bigrams_vector_pattern<-paste(institution_list_bigrams_vector, collapse="|")

institution_list_bigrams_vector_pattern <- paste("\\b(?i)(", institution_list_bigrams_vector_pattern, ")\\b", sep="")

gh_extra_company <- gh_extra_company%>%
  mutate(institution_bigram_match_company = if_else(str_detect(c_company, institution_list_bigrams_vector_pattern) == T, T, F))%>%
  mutate(institution_bigram_match_company= replace_na(institution_bigram_match_company, FALSE))

#table(gh_extra_company$bigram_match_company)
table(filter(gh_extra_company, !is.gov)$institution_bigram_match_company)
gh_extra_company <- gh_extra_company%>%
  mutate(is.gov = if_else(institution_bigram_match_company==T, T, is.gov))

table(gh_extra_company$is.gov)
```

## Catch the fish--final matching
```{r}
####final step
gh_extra_company <- gh_extra_company%>%
  mutate(is.gov.extra = if_else(str_detect(c_company, "\\b(?i)(gov|government|bureau|federalhomeland security|fbi|cia|census|united state army|usarmy)\\b") == T, T, F))%>%
  mutate(is.gov.extra= replace_na(is.gov.extra, FALSE))

#check <- filter(gh_extra_company, !is.gov, is.gov.extra == T)

nrow(filter(gh_extra_company, !is.gov, is.gov.extra == T))

gh_extra_company <- gh_extra_company%>%
    mutate(is.gov = if_else(is.gov.extra==T, T, is.gov))

table(gh_extra_company$is.gov)
```

# Check internaitonal or domestic
```{r}
# check <- gh_extra_company%>%
#   filter(is.gov)
# table(is.na(check$domain_type))
```


# Prepare for writing to pgAdmin
```{r}
nrow(gh_extra_company)-nrow(gh_extra) #check that we didn't lose any gh users
gh_extra_company_final <- gh_extra_company%>%
  select(login, is.gov)%>%
  mutate(is.gov= replace_na(is.gov, FALSE))%>%
  rename(is_gov = is.gov)%>%
  filter(is_gov)

#table(gh_extra_company_final$is_gov)

# reconnecting to the database 
conn <- dbConnect(drv = PostgreSQL(), 
                  dbname = "sdad", 
                  host = "10.250.124.195", 
                  port = 5432, 
                  user = Sys.getenv("db_userid"), 
                  password = Sys.getenv("db_pwd"))
# writing the new gh_extra_company_final table to postgis_2
dbWriteTable(conn, c("gh", "sna_ctr_gov"), gh_extra_company_final)
# disconnect from postgresql database  
dbDisconnect(conn)
```

