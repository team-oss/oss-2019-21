& is_gov != 1 & is_business != 1 & is_household != 1)
leftover_counts <- leftovers %>%
count(company) %>%
arrange(-n); leftover_counts
leftover_counts
View(business_users)
View(nonprofit_users)
rm(list = ls())
# load packages
for (pkg in c("tidyverse", "data.table", "countrycode", "tidyorgs",
"R.utils", "RPostgreSQL")) {library(pkg, character.only = TRUE)}
setwd("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data")
raw_ctr_data <- readRDS("../data/github_sectored_101321.rds") #%>%
#rename(is_academic = academic)
# academic_users <- raw_ctr_data %>%
#   select(login, organization, is_academic, org_type) %>%
#   filter(is_academic == 1)
# academic_users
# implementing daniel's approaches
legal_entities <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/curatedLegalEntitesRaw.csv", header=FALSE)
legal_entities <- legal_entities %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
legal_entities$strings <- substring(legal_entities$strings, 2)
legal_entities$strings <- substr(legal_entities$strings,1, nchar(legal_entities$strings)-1)
symbol_strings <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/symbolRemove.csv", header=FALSE)
symbol_strings <- symbol_strings %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
symbol_strings$strings <- substring(symbol_strings$strings, 2)
symbol_strings$strings <- substr(symbol_strings$strings,1, nchar(symbol_strings$strings)-1)
symbol_strings <- symbol_strings %>% slice(-17:-20)
curated_domains <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/curatedDomains.csv", header=FALSE)
curated_domains <- curated_domains %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
curated_domains$strings <- substring(curated_domains$strings, 2)
curated_domains$strings <- substr(curated_domains$strings,1, nchar(curated_domains$strings)-1)
data_to_classify <- raw_ctr_data %>%
select(login, company, location, email) %>%
mutate(email = tolower(email)) %>%
filter(!is.na(company) | (!is.na(email) &
!grepl("gmail.com$|hotmail.com$|protonmail.com$|qq.com$|yahoo.com$|163.com$|126.com$|outlook.com$|live.com$|foxmail.com$|me.com$|icloud.com$", email)))
data_to_classify <- data_to_classify %>%
mutate(company = trimws(company),
company = tolower(company)) %>%
mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(legal_entities$strings),
"zqx|, Inc.)"), collapse = "|"), "")) %>%
mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(symbol_strings$strings),
", $|,$|zqx)"), collapse = "|"), "")) %>%
mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(curated_domains$strings),
"zqx)"), collapse = "|"), ""))
# null values
null_values <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/nullKeys.csv", header=FALSE)
null_values <- null_values %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
null_values$strings <- substring(null_values$strings, 2)
null_values$strings <- substr(null_values$strings,1, nchar(null_values$strings)-1)
data_to_classify <- data_to_classify %>%
mutate(is_null = ifelse(test = str_detect(string = company,
pattern = paste(c("\\b(?i)(z3x", na.omit(null_values$strings), "z3x)\\b"), collapse = "|")),
yes = 1, no = NA)) %>%
mutate(is_null = ifelse(!str_detect(company, "[a-z]"), 1, is_null)) %>%
mutate(is_null = ifelse(str_detect(company, "\\b(?i)(^china$|^japan$|^taiwan$|^indonesia$|^beijing$|^retired$|^germany$|^test$|^anonymous$|^open source$|^full stack developer$|^developer$|^software engineer$|^software$|^undefined$|^own$|^secret$|^nope$|^nil$|^unknown$|^nothing$|^non$|^dev$|^localhost$|^confidential$|^data scientist$|^null$|null|data scientist|localhost|dev|confidential|internet|no)\\b"), 1, is_null)) %>% mutate(is_null = replace_na(is_null, 0)) #%>%
#filter(is_null != 1)
null_users <- data_to_classify %>%
filter(is_null == 1)
null_users; rm(null_values, legal_entities, curated_domains, symbol_strings)
View(null_users)
# implementing daniel's approaches
legal_entities <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/curatedLegalEntitesRaw.csv", header=FALSE)
legal_entities <- legal_entities %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
legal_entities$strings <- substring(legal_entities$strings, 2)
legal_entities$strings <- substr(legal_entities$strings,1, nchar(legal_entities$strings)-1)
symbol_strings <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/symbolRemove.csv", header=FALSE)
symbol_strings <- symbol_strings %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
symbol_strings$strings <- substring(symbol_strings$strings, 2)
symbol_strings$strings <- substr(symbol_strings$strings,1, nchar(symbol_strings$strings)-1)
symbol_strings <- symbol_strings %>% slice(-17:-20)
curated_domains <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/curatedDomains.csv", header=FALSE)
curated_domains <- curated_domains %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
curated_domains$strings <- substring(curated_domains$strings, 2)
curated_domains$strings <- substr(curated_domains$strings,1, nchar(curated_domains$strings)-1)
data_to_classify <- raw_ctr_data %>%
select(login, company, location, email) %>%
mutate(email = tolower(email)) %>%
filter(!is.na(company) | (!is.na(email) &
!grepl("gmail.com$|hotmail.com$|protonmail.com$|qq.com$|yahoo.com$|163.com$|126.com$|outlook.com$|live.com$|foxmail.com$|me.com$|icloud.com$", email)))
data_to_classify <- data_to_classify %>%
mutate(company = trimws(company),
company = tolower(company)) %>%
mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(legal_entities$strings),
"zqx|, Inc.)"), collapse = "|"), "")) %>%
mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(symbol_strings$strings),
", $|,$|zqx)"), collapse = "|"), "")) %>%
mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(curated_domains$strings),
"zqx)"), collapse = "|"), ""))
# null values
null_values <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/nullKeys.csv", header=FALSE)
null_values <- null_values %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
null_values$strings <- substring(null_values$strings, 2)
null_values$strings <- substr(null_values$strings,1, nchar(null_values$strings)-1)
data_to_classify <- data_to_classify %>%
mutate(is_null = ifelse(test = str_detect(string = company,
pattern = paste(c("\\b(?i)(z3x", na.omit(null_values$strings), "z3x)\\b"), collapse = "|")),
yes = 1, no = NA)) %>%
mutate(is_null = ifelse(!str_detect(company, "[a-z]"), 1, is_null)) %>%
mutate(is_null = ifelse(str_detect(company, "\\b(?i)(^china$|^japan$|^taiwan$|^indonesia$|^beijing$|^retired$|^germany$|^test$|^anonymous$|^open source$|^full stack developer$|^developer$|^software engineer$|^software$|^undefined$|^own$|^secret$|^nope$|^nil$|^unknown$|^nothing$|^non$|^dev$|^localhost$|^confidential$|^data scientist$|^null$|null|data scientist|localhost|dev|confidential|internet|(?<![a-z])no(?![a-z]))\\b"), 1, is_null)) %>% mutate(is_null = replace_na(is_null, 0)) #%>%
#filter(is_null != 1)
null_users <- data_to_classify %>%
filter(is_null == 1)
null_users; rm(null_values, legal_entities, curated_domains, symbol_strings)
# household
household <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/individualKeys.csv", header=FALSE)
household <- household %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
household$strings <- substring(household$strings, 2)
household$strings <- substr(household$strings,1, nchar(household$strings)-1)
data_to_classify <- data_to_classify %>%
mutate(company = tolower(company),
#company = str_replace_all(company, "\\/", " "),
is_household = ifelse(test = str_detect(string = company,
pattern = paste(c("\\b(?i)(z3x", na.omit(household$strings),
"^self-employed$|self-employed|^self employed$|^unemployed$|^available for hire$|for hire$|^home office$|free|my own|^home$|^independant$|^private$|private|^self$|self|independent|indie|independiente)\\b"), collapse = "|")), yes = 1, no = 0)) %>%
mutate(is_household = replace_na(is_household, 0))
household_users <- data_to_classify %>%
filter(is_household == 1)
household_users; rm(household)
data_to_classify <- data_to_classify %>%
detect_academic(login, company, organization, email) %>%
rename(is_academic = academic)
academic_users <- data_to_classify %>%
filter(is_academic == 1); academic_users
data_to_classify <- data_to_classify %>%
select(-organization) %>%
detect_nonprofit(login, company, organization, email) %>%
rename(is_nonprofit = nonprofit)
nonprofit_users <- data_to_classify %>%
filter(is_nonprofit == 1); nonprofit_users
#data_to_classify <- data_to_classify %>% select(-organization, -is_gov)
data_to_classify <- data_to_classify %>%
select(-organization) %>%
detect_government(login, company, organization, email) %>%
rename(is_gov = government)
rm(list = ls())
library(tidyverse)
library(tidyorgs)
library(diverstidy)
library(RPostgreSQL)
# analyzed on 10/15/21 and then updated with fractions on 10/20/21
setwd("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data")
ctrs_by_ctry <- readRDS("../data/github_sectored_101321.rds")
with_country_data <- ctrs_by_ctry %>%
filter(!is.na(country) | !is.na(ac_country)) %>%
mutate(country = if_else(is.na(country), ac_country, country)) %>%
mutate(country = str_replace(country, "Jersey\\|", ""),
country = str_replace(country, "Jersey", "United States"),
fraction = (1 / (str_count(country, "\\|") + 1))) %>%
select(login, country, fraction)
with_country_data <- ctrs_by_ctry %>%
filter(!is.na(country) | !is.na(ac_country)) %>%
mutate(country = if_else(is.na(country), ac_country, country)) %>%
mutate(country = str_replace(country, "Jersey\\|", ""),
country = str_replace(country, "Jersey", "United States"),
fraction = (1 / (str_count(country, "\\|") + 1))) %>%
select(login, country, fraction) %>%
mutate(country = strsplit(as.character(country), "\\|"))
with_country_data <- ctrs_by_ctry %>%
filter(!is.na(country) | !is.na(ac_country)) %>%
mutate(country = if_else(is.na(country), ac_country, country)) %>%
mutate(country = str_replace(country, "Jersey\\|", ""),
country = str_replace(country, "Jersey", "United States"),
fraction = (1 / (str_count(country, "\\|") + 1))) %>%
select(login, country, fraction) %>%
mutate(country = strsplit(as.character(country), "\\|")) %>%
unnest(country)
View(with_country_data)
with_country_data <- ctrs_by_ctry %>%
filter(!is.na(country) | !is.na(ac_country)) %>%
mutate(country = if_else(is.na(country), ac_country, country)) %>%
mutate(country = str_replace(country, "Jersey\\|", ""),
country = str_replace(country, "Jersey", "United States"),
fraction = (1 / (str_count(country, "\\|") + 1))) %>%
select(login, country, fraction) %>%
mutate(country = strsplit(as.character(country), "\\|")) %>%
unnest(country) %>%
drop_na(country) %>%
arrange(fraction)
country_counts <- with_country_data %>%
unnest_legacy(country = base::strsplit(country, "\\|")) %>%
filter(country != "NA") %>%
group_by(country) %>%
summarise(users = sum(fraction)) %>%
arrange(-users)
sum(country_counts$users)
unique(ctrs_by_ctry$login)
nrow(unique(ctrs_by_ctry$login))
sum(unique(ctrs_by_ctry$login))
nrow(unique(ctrs_by_ctry$login))
ctrs_by_ctry %>%
distinct(login)
library(tidytable)
conn <- dbConnect(drv = PostgreSQL(), dbname = "sdad",
host = "10.250.124.195", port = 5432,
user = Sys.getenv("db_userid"), password = Sys.getenv("db_pwd"))
counts_by_year <- dbGetQuery(conn, "SELECT * FROM gh_cost.cost_by_year_0919_dd_nmrc_jbsc;")
dbDisconnect(conn)
counts_by_year <- data.table::as.data.table(counts_by_year)
#COST BASED ON Additions
counts_by_year[,person_months := round(2.5 * (2.4 * (additions/1000)^1.05)^0.38,2)]
conn <- dbConnect(drv = PostgreSQL(), dbname = "sdad",
host = "10.250.124.195", port = 5432,
user = Sys.getenv("db_userid"), password = Sys.getenv("db_pwd"))
counts_by_country <- dbGetQuery(conn, "SELECT * FROM gh_cost.cost_by_country_annual_0919_dd_nmrc_jbsc_102021;")
dbDisconnect(conn)
chk <- counts_by_country %>%
slice(1:100)
View(chk)
repos_geo_joined <- counts_by_country %>%
#select(-year) %>%
rename.(geo_commits = commits,
geo_additions = additions,
geo_deletions = deletions,
geo_sum = sum_adds_dels,
geo_net = net_adds_dels) %>%
left_join(counts_by_year, by = c("slug", "year")) %>%
select(slug, country, year, everything())
chk <- repos_geo_joined %>%
slice(1:100)
round(2.5 * (2.4 * (2/1000)^1.05)^0.38,2)
round(2.5 * (2.4 * (650/1000)^1.05)^0.38,2)
rm(list = ls())
#library(tidyverse)
#library(RPostgreSQL)
library(tidytable)
conn <- dbConnect(drv = PostgreSQL(), dbname = "sdad",
host = "10.250.124.195", port = 5432,
user = Sys.getenv("db_userid"), password = Sys.getenv("db_pwd"))
counts_by_year <- dbGetQuery(conn, "SELECT * FROM gh_cost.cost_by_year_0919_dd_nmrc_jbsc;")
dbDisconnect(conn)
counts_by_year <- data.table::as.data.table(counts_by_year)
#COST BASED ON Additions
counts_by_year[,person_months := round(2.5 * (2.4 * (additions/1000)^1.05)^0.38,2)]
conn <- dbConnect(drv = PostgreSQL(), dbname = "sdad",
host = "10.250.124.195", port = 5432,
user = Sys.getenv("db_userid"), password = Sys.getenv("db_pwd"))
counts_by_country <- dbGetQuery(conn, "SELECT * FROM gh_cost.cost_by_country_annual_0919_dd_nmrc_jbsc_103121;")
dbDisconnect(conn)
repos_geo_joined <- counts_by_country %>%
#select(-year) %>%
rename.(geo_commits = commits,
geo_additions = additions,
geo_deletions = deletions,
geo_sum = sum_adds_dels,
geo_net = net_adds_dels) %>%
left_join(counts_by_year, by = c("slug", "year")) %>%
select(slug, country, year, everything())
repos_geo_joined <- counts_by_country %>%
#select(-year) %>%
rename.(geo_commits = commits,
geo_additions = additions,
geo_deletions = deletions
#geo_sum = sum_adds_dels,
#geo_net = net_adds_dels
) %>%
left_join(counts_by_year, by = c("slug", "year")) %>%
select(slug, country, year, everything())
repos_geo_joined <- counts_by_country %>%
#select(-year) %>%
rename.(#geo_commits = commits,
geo_additions = additions,
geo_deletions = deletions
#geo_sum = sum_adds_dels,
#geo_net = net_adds_dels
) %>%
left_join(counts_by_year, by = c("slug", "year")) %>%
select(slug, country, year, everything())
repos_geo_joined <- counts_by_country %>%
#select(-year) %>%
rename.(#geo_commits = commits,
geo_additions = fr_additions,
geo_deletions = fr_deletions
#geo_sum = sum_adds_dels,
#geo_net = net_adds_dels
) %>%
left_join(counts_by_year, by = c("slug", "year")) %>%
select(slug, country, year, everything())
repos_geo_joined <- repos_geo_joined %>%
rename.(repo_additions = additions,
repo_deletions = deletions) %>%
mutate.(geo_fraction = round(geo_additions / repo_additions, 3),
geo_person_months = geo_fraction * person_months) %>%
arrange.(slug, country, geo_fraction)
repos_geo_joined$geo_person_months[is.nan(repos_geo_joined$geo_person_months)] <- 0
costs_by_country <- repos_geo_joined %>%
group_by(country, year) %>%
summarize(person_months = sum(geo_person_months)) %>%
arrange(country, year); costs_by_country
costs_by_country_wide <- costs_by_country %>%
pivot_wider(names_from = year, values_from = person_months) %>%
arrange(-`2019`)
View(costs_by_country_wide)
costs_by_country_wide_r <- costs_by_country %>%
group_by(year) %>%
summarise(person_months = sum(person_months)) %>%
pivot_wider(names_from = year, values_from = person_months) %>%
mutate(country = "All Countries") %>%
select(country, everything()) %>%
bind_rows(costs_by_country_wide)
View(costs_by_country_wide_r)
costs_by_country_wide <- costs_by_country %>%
group_by(year) %>%
summarise(person_months = sum(person_months)) %>%
pivot_wider(names_from = year, values_from = person_months) %>%
mutate(country = "All Countries") %>%
select(country, everything()) %>%
bind_rows(costs_by_country_wide)
costs_by_country_wide <- costs_by_country %>%
pivot_wider(names_from = year, values_from = person_months) %>%
arrange(-`2019`)
costs_by_country_wide <- costs_by_country %>%
group_by(year) %>%
summarise(person_months = sum(person_months)) %>%
pivot_wider(names_from = year, values_from = person_months) %>%
mutate(country = "Totals") %>%
select(country, everything()) %>%
bind_rows(costs_by_country_wide)
setwd("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/cost_estimations")
write_csv(costs_by_country_simp_wide, "person_months_by_country_simp_103121.csv")
costs_by_country_simp_wide <- costs_by_country_simplified %>%
pivot_wider(names_from = year, values_from = person_months)
setwd("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/cost_estimations")
write_csv(costs_by_country_wide, "person_months_by_country_103121.csv")
costs_by_country_simplified <- costs_by_country %>%
mutate(geo_binary = "Other Countries") %>%
mutate(geo_binary = ifelse(country == "Missing", "Missing",
ifelse(country == "United States", "United States", geo_binary))) %>%
group_by(geo_binary, year) %>%
summarize(person_months = sum(person_months)) %>%
rename(geography = geo_binary)
costs_by_country_simp_wide <- costs_by_country_simplified %>%
pivot_wider(names_from = year, values_from = person_months)
setwd("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/cost_estimations")
write_csv(costs_by_country_simp_wide, "person_months_by_country_simp_103121.csv")
rm(list = ls())
# load packages
for (pkg in c("tidyverse", "data.table", "countrycode", "tidyorgs",
"R.utils", "RPostgreSQL")) {library(pkg, character.only = TRUE)}
setwd("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data")
raw_ctr_data <- readRDS("../data/github_sectored_101321.rds")
setwd("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data")
users_with_countries <- readRDS("../data/github_wcountries_102521.rds")
View(users_with_countries)
library(RPostgreSQL)
conn <- dbConnect(drv = PostgreSQL(), dbname = "sdad",
host = "10.250.124.195", port = 5432,
user = Sys.getenv("db_userid"), password = Sys.getenv("db_pwd"))
users_with_countries <- dbGetQuery(conn, "SELECT * FROM gh_cost.user_country_fractions;")
dbDisconnect(conn)
View(users_with_countries)
# implementing daniel's approaches
legal_entities <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/curatedLegalEntitesRaw.csv", header=FALSE)
legal_entities <- legal_entities %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
legal_entities$strings <- substring(legal_entities$strings, 2)
legal_entities$strings <- substr(legal_entities$strings,1, nchar(legal_entities$strings)-1)
symbol_strings <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/symbolRemove.csv", header=FALSE)
symbol_strings <- symbol_strings %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
symbol_strings$strings <- substring(symbol_strings$strings, 2)
symbol_strings$strings <- substr(symbol_strings$strings,1, nchar(symbol_strings$strings)-1)
symbol_strings <- symbol_strings %>% slice(-17:-20)
curated_domains <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/curatedDomains.csv", header=FALSE)
curated_domains <- curated_domains %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
curated_domains$strings <- substring(curated_domains$strings, 2)
curated_domains$strings <- substr(curated_domains$strings,1, nchar(curated_domains$strings)-1)
data_to_classify <- raw_ctr_data %>%
select(login, company, location, email) %>%
mutate(email = tolower(email)) %>%
filter(!is.na(company) | (!is.na(email) &
!grepl("gmail.com$|hotmail.com$|protonmail.com$|qq.com$|yahoo.com$|163.com$|126.com$|outlook.com$|live.com$|foxmail.com$|me.com$|icloud.com$", email)))
data_to_classify <- data_to_classify %>%
mutate(company = trimws(company),
company = tolower(company)) %>%
mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(legal_entities$strings),
"zqx|, Inc.)"), collapse = "|"), "")) %>%
mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(symbol_strings$strings),
", $|,$|zqx)"), collapse = "|"), "")) %>%
mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(curated_domains$strings),
"zqx)"), collapse = "|"), ""))
# null values
null_values <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/nullKeys.csv", header=FALSE)
null_values <- null_values %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
null_values$strings <- substring(null_values$strings, 2)
null_values$strings <- substr(null_values$strings,1, nchar(null_values$strings)-1)
data_to_classify <- data_to_classify %>%
mutate(is_null = ifelse(test = str_detect(string = company,
pattern = paste(c("\\b(?i)(z3x", na.omit(null_values$strings), "z3x)\\b"), collapse = "|")),
yes = 1, no = NA)) %>%
mutate(is_null = ifelse(!str_detect(company, "[a-z]"), 1, is_null)) %>%
mutate(is_null = ifelse(str_detect(company, "\\b(?i)(^china$|^japan$|^taiwan$|^indonesia$|^beijing$|^retired$|^germany$|^test$|^anonymous$|^open source$|^full stack developer$|^developer$|^software engineer$|^software$|^undefined$|^own$|^secret$|^nope$|^nil$|^unknown$|^nothing$|^non$|^dev$|^localhost$|^confidential$|^data scientist$|^null$|null|data scientist|localhost|dev|confidential|internet|(?<![a-z])no(?![a-z]))\\b"), 1, is_null)) %>% mutate(is_null = replace_na(is_null, 0)) #%>%
#filter(is_null != 1)
null_users <- data_to_classify %>%
filter(is_null == 1)
null_users; rm(null_values, legal_entities, curated_domains, symbol_strings)
# household
household <- read.csv("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data/ossPy-files/individualKeys.csv", header=FALSE)
household <- household %>%
rename(strings = V1) %>%
mutate(strings = as.character(strings))
household$strings <- substring(household$strings, 2)
household$strings <- substr(household$strings,1, nchar(household$strings)-1)
data_to_classify <- data_to_classify %>%
mutate(company = tolower(company),
#company = str_replace_all(company, "\\/", " "),
is_household = ifelse(test = str_detect(string = company,
pattern = paste(c("\\b(?i)(z3x", na.omit(household$strings),
"^self-employed$|self-employed|^self employed$|^unemployed$|^available for hire$|for hire$|^home office$|free|my own|^home$|^independant$|^private$|private|^self$|self|independent|indie|independiente)\\b"), collapse = "|")), yes = 1, no = 0)) %>%
mutate(is_household = replace_na(is_household, 0))
household_users <- data_to_classify %>%
filter(is_household == 1)
household_users; rm(household)
data_to_classify <- data_to_classify %>%
detect_academic(login, company, organization, email) %>%
rename(is_academic = academic)
academic_users <- data_to_classify %>%
filter(is_academic == 1); academic_users
data_to_classify <- data_to_classify %>%
select(-organization) %>%
detect_nonprofit(login, company, organization, email) %>%
rename(is_nonprofit = nonprofit)
nonprofit_users <- data_to_classify %>%
filter(is_nonprofit == 1); nonprofit_users
#data_to_classify <- data_to_classify %>% select(-organization, -is_gov)
data_to_classify <- data_to_classify %>%
select(-organization) %>%
detect_government(login, company, organization, email) %>%
rename(is_gov = government)
government_users <- data_to_classify %>%
filter(is_gov == 1); government_users
# data_to_classify <- data_to_classify %>% select(-organization, -is_business)
data_to_classify <- data_to_classify %>%
select(-organization) %>%
mutate(company = sub(".*\\|", "", company),
company = trimws(company, which = "both")) %>%
detect_business(login, company, organization, email) %>%
rename(is_business = business) %>%
select(everything(), organization)
business_users <- data_to_classify %>%
filter(is_business == 1); business_users
leftovers <- data_to_classify %>%
filter(!is.na(company) & is_academic != 1 & is_null != 1 & is_nonprofit != 1
& is_gov != 1 & is_business != 1 & is_household != 1
& !grepl("blockchain|hse|hust|none|mail group|unam|uiuc", company))
leftover_counts <- leftovers %>%
mutate(company = sub(".*\\|", "", company),
company = trimws(company, which = "both")) %>%
count(company) %>%
filter(n < 26) %>%
arrange(-n); leftover_counts
#
above_five <- leftover_counts %>%
filter(n > 5)
data_to_classify <- data_to_classify %>%
mutate(company = sub(".*\\|", "", company)) %>%
mutate(is_business = ifelse(test = str_detect(string = company,
pattern = paste(c("\\b(?i)(z3x", na.omit(above_five$company), "z3x)\\b"), collapse = "$|^")),
yes = 1, no = is_business))
business_users <- data_to_classify %>%
mutate(company = sub(".*\\|", "", company),
company = trimws(company, which = "both")) %>%
filter(is_business == 1)
business_users <- business_users %>%
mutate(organization = replace_na(organization, "Misc. Business"))
business_users
leftovers <- data_to_classify %>%
filter(is_academic != 1 & is_null != 1 & is_nonprofit != 1
& is_gov != 1 & is_business != 1 & is_household != 1)
leftover_counts <- leftovers %>%
count(company) %>%
arrange(-n); leftover_counts
sum(leftover_counts$n)
nrow(academic_users)
nrow(business_users)
nrow(government_users)
nrow(nonprofit_users)
nrow(household_users)
rm(list = ls())
# load packages
for (pkg in c("tidyverse", "data.table", "countrycode", #"tidyorgs",
"R.utils", "RPostgreSQL")) {library(pkg, character.only = TRUE)}
setwd("/sfs/qumulo/qhome/kb7hp/git/oss-2020/data")
raw_ctr_data <- readRDS("../data/github_sectored_101321.rds")
government_users %>%
group_by(organization) %>%
count()
